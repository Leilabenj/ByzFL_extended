
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>byzfl.aggregators.aggregators &#8212; ByzFL</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=613b6425" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/byzfl/aggregators/aggregators';</script>
    <script src="../../../_static/custom-icon.js?v=74687d30"></script>
    <link rel="icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/byzfl_logo.png" class="logo__image only-light" alt="ByzFL - Home"/>
    <img src="../../../_static/byzfl_logo.png" class="logo__image only-dark pst-js-only" alt="ByzFL - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../aggregators/index.html">
    Aggregators
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../attacks/index.html">
    Attacks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../fed_framework/index.html">
    Federated Learning Framework
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../team/index.html">
    Our Team
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/LPD-EPFL/byzfl" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/byzfl/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../aggregators/index.html">
    Aggregators
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../attacks/index.html">
    Attacks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../fed_framework/index.html">
    Federated Learning Framework
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../team/index.html">
    Our Team
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/LPD-EPFL/byzfl" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/byzfl/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">byzfl.aggregators.aggregators</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for byzfl.aggregators.aggregators</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">byzfl.utils.misc</span> <span class="kn">import</span> <span class="n">check_vectors_type</span><span class="p">,</span> <span class="n">distance_tool</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">ones_vector</span><span class="p">,</span> <span class="n">random_tool</span>

<div class="viewcode-block" id="Average">
<a class="viewcode-back" href="../../../aggregators/classes/average.html#byzfl.Average">[docs]</a>
<span class="k">class</span> <span class="nc">Average</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Description</span>
<span class="sd">    -----------</span>

<span class="sd">    Compute the average along the first axis:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \mathrm{Average} (x_1, \dots, x_n) = \frac{1}{n} \sum_{j = 1}^{n} x_j</span>

<span class="sd">    where</span>

<span class="sd">    - :math:`x_1, \dots, x_n` are the input vectors, which conceptually correspond to gradients submitted by honest and Byzantine participants during a training iteration.</span>

<span class="sd">        </span>
<span class="sd">    Initialization parameters</span>
<span class="sd">    -------------------------</span>
<span class="sd">    None</span>
<span class="sd">        </span>
<span class="sd">    Calling the instance</span>
<span class="sd">    --------------------</span>

<span class="sd">    Input parameters</span>
<span class="sd">    ----------------</span>
<span class="sd">    vectors: numpy.ndarray, torch.Tensor, list of numpy.ndarray or list of torch.Tensor</span>
<span class="sd">        A set of vectors, matrix or tensors.</span>
<span class="sd">        </span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    :numpy.ndarray or torch.Tensor</span>
<span class="sd">        The data type of the output will be the same as the input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    &gt;&gt;&gt; import byzfl</span>
<span class="sd">    &gt;&gt;&gt; agg = byzfl.Average()</span>

<span class="sd">    Using numpy arrays</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([[1., 2., 3.],       # np.ndarray</span>
<span class="sd">    &gt;&gt;&gt;               [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;               [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([4. 5. 6.])</span>
<span class="sd">            </span>
<span class="sd">    Using torch tensors</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = torch.tensor([[1., 2., 3.],   # torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;                   [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;                   [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([4., 5., 6.])</span>

<span class="sd">    Using list of numpy arrays</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = [np.array([1., 2., 3.]),      # list of np.ndarray  </span>
<span class="sd">    &gt;&gt;&gt;      np.array([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      np.array([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([4., 5., 6.])</span>

<span class="sd">    Using list of torch tensors</span>

<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = [torch.tensor([1., 2., 3.]),  # list of torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([4., 5., 6.])</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>        
    
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectors</span><span class="p">):</span>
        <span class="n">tools</span><span class="p">,</span> <span class="n">vectors</span> <span class="o">=</span> <span class="n">check_vectors_type</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tools</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>



<div class="viewcode-block" id="Median">
<a class="viewcode-back" href="../../../aggregators/classes/median.html#byzfl.Median">[docs]</a>
<span class="k">class</span> <span class="nc">Median</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Description</span>
<span class="sd">    -----------</span>

<span class="sd">    Compute the coordinate-wise median along the first axis [1]_:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \big[\mathrm{Median} \ (x_1, \dots, x_n)\big]_k = \mathrm{median} \big(\big[x_1\big]_k, \dots, \big[x_n\big]_k\big)</span>

<span class="sd">    where</span>

<span class="sd">    - :math:`x_1, \dots, x_n` are the input vectors, which conceptually correspond to gradients submitted by honest and Byzantine participants during a training iteration.</span>

<span class="sd">    - \\(\\big[\\cdot\\big]_k\\) refers to the \\(k\\)-th coordinate.</span>

<span class="sd">    - :math:`\mathrm{median}` refers to the median of :math:`n` scalars.</span>


<span class="sd">    Initialization parameters</span>
<span class="sd">    -------------------------</span>
<span class="sd">    None</span>
<span class="sd">        </span>
<span class="sd">    Calling the instance</span>
<span class="sd">    --------------------</span>

<span class="sd">    Input parameters</span>
<span class="sd">    ----------------</span>
<span class="sd">    vectors: numpy.ndarray, torch.Tensor, list of numpy.ndarray or list of torch.Tensor</span>
<span class="sd">        A set of vectors, matrix or tensors.</span>
<span class="sd">        </span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    :numpy.ndarray or torch.Tensor</span>
<span class="sd">        The data type of the output will be the same as the input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    &gt;&gt;&gt; import byzfl</span>
<span class="sd">    &gt;&gt;&gt; agg = byzfl.Median()</span>

<span class="sd">    Using numpy arrays</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([[1., 2., 3.],       # np.ndarray</span>
<span class="sd">    &gt;&gt;&gt;               [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;               [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([4. 5. 6.])</span>
<span class="sd">            </span>
<span class="sd">    Using torch tensors</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = torch.tensor([[1., 2., 3.],   # torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;                   [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;                   [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([4., 5., 6.])</span>

<span class="sd">    Using list of numpy arrays</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = [np.array([1., 2., 3.]),      # list of np.ndarray </span>
<span class="sd">    &gt;&gt;&gt;      np.array([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      np.array([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([4., 5., 6.])</span>

<span class="sd">    Using list of torch tensors</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = [torch.tensor([1., 2., 3.]),  # list of torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([4., 5., 6.])</span>

<span class="sd">     References</span>
<span class="sd">    ----------</span>

<span class="sd">    .. [1] Dong Yin, Yudong Chen, Ramchandran Kannan, and Peter Bartlett. Byzantine-robust distributed</span>
<span class="sd">           learning: Towards optimal statistical rates. In International Conference on Machine Learning, pp.5650–5659. PMLR, 2018.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectors</span><span class="p">):</span>
        <span class="n">tools</span><span class="p">,</span> <span class="n">vectors</span> <span class="o">=</span> <span class="n">check_vectors_type</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tools</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>



<div class="viewcode-block" id="TrMean">
<a class="viewcode-back" href="../../../aggregators/classes/trmean.html#byzfl.TrMean">[docs]</a>
<span class="k">class</span> <span class="nc">TrMean</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Description</span>
<span class="sd">    -----------</span>

<span class="sd">    Compute the trimmed mean (or truncated mean) along the first axis [1]_:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \big[\mathrm{TrMean}_{f} \ (x_1, \dots, x_n)\big]_k = \frac{1}{n - 2f}\sum_{j = f+1}^{n-f} \big[x_{\pi(j)}\big]_k</span>
<span class="sd">    </span>
<span class="sd">    where</span>

<span class="sd">    - :math:`x_1, \dots, x_n` are the input vectors, which conceptually correspond to gradients submitted by honest and Byzantine participants during a training iteration.</span>

<span class="sd">    - :math:`f` conceptually represents the expected number of Byzantine vectors.</span>
<span class="sd">    </span>
<span class="sd">    - \\(\\big[\\cdot\\big]_k\\) refers to the \\(k\\)-th coordinate.</span>

<span class="sd">    - \\(\\pi\\) denotes a permutation on \\(\\big[n\\big]\\) that sorts the \\(k\\)-th</span>
<span class="sd">      coordinate of the input vectors in non-decreasing order, i.e., </span>
<span class="sd">      \\(\\big[x_{\\pi(1)}\\big]_k \\leq ...\\leq \\big[x_{\\pi(n)}\\big]_k\\).</span>
<span class="sd">    </span>
<span class="sd">    In other words, TrMean removes the \\(f\\) largest and \\(f\\) smallest coordinates per dimension, and then applies the average over the remaining coordinates.</span>

<span class="sd">    Initialization parameters</span>
<span class="sd">    --------------------------</span>
<span class="sd">    f : int, optional</span>
<span class="sd">        Number of faulty vectors. Set to 0 by default.</span>
<span class="sd">    </span>
<span class="sd">    Calling the instance</span>
<span class="sd">    --------------------</span>

<span class="sd">    Input parameters</span>
<span class="sd">    ----------------</span>
<span class="sd">    vectors: numpy.ndarray, torch.Tensor, list of numpy.ndarray or list of torch.Tensor</span>
<span class="sd">        A set of vectors, matrix or tensors.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    :numpy.ndarray or torch.Tensor</span>
<span class="sd">        The data type of the output will be the same as the input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    &gt;&gt;&gt; import byzfl</span>
<span class="sd">    &gt;&gt;&gt; agg = byzfl.TrMean(1)</span>

<span class="sd">    Using numpy arrays</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([[1., 2., 3.],       # np.ndarray</span>
<span class="sd">    &gt;&gt;&gt;               [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;               [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([4. 5. 6.])</span>
<span class="sd">            </span>
<span class="sd">    Using torch tensors</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = torch.tensor([[1., 2., 3.],   # torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;                   [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;                   [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([4., 5., 6.])</span>

<span class="sd">    Using list of numpy arrays</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = [np.array([1., 2., 3.]),      # list of np.ndarray  </span>
<span class="sd">    &gt;&gt;&gt;      np.array([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      np.array([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([4., 5., 6.])</span>

<span class="sd">    Using list of torch tensors</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = [torch.tensor([1., 2., 3.]),  # list of torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([4., 5., 6.])</span>


<span class="sd">    References</span>
<span class="sd">    ----------</span>

<span class="sd">    .. [1] Dong Yin, Yudong Chen, Ramchandran Kannan, and Peter Bartlett. Byzantine-robust distributed</span>
<span class="sd">           learning: Towards optimal statistical rates. In International Conference on Machine Learning, pp.5650–5659. PMLR, 2018.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">f</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;f must be a non-negative integer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">=</span> <span class="n">f</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectors</span><span class="p">):</span>
        <span class="n">tools</span><span class="p">,</span> <span class="n">vectors</span> <span class="o">=</span> <span class="n">check_vectors_type</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">&gt;=</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cannot tolerate 2f ≥ n. Got f=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="si">}</span><span class="s2">, n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">avg</span> <span class="o">=</span> <span class="n">Average</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">avg</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="n">selected_vectors</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">:</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">tools</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">selected_vectors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>



<div class="viewcode-block" id="GeometricMedian">
<a class="viewcode-back" href="../../../aggregators/classes/geometric_median.html#byzfl.GeometricMedian">[docs]</a>
<span class="k">class</span> <span class="nc">GeometricMedian</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Description</span>
<span class="sd">    -----------</span>

<span class="sd">    Apply the smoothed Weiszfeld algorithm [1]_ to obtain the approximate geometric median \\(y\\):</span>

<span class="sd">    .. math::</span>

<span class="sd">        \mathrm{GeometricMedian}_{\nu, T} \ (x_1, \dots, x_n) \in \argmin_{y \in \mathbb{R}^d}\sum_{i = 1}^{n} \big|\big|y - x_i\big|\big|_2</span>
<span class="sd">    </span>
<span class="sd">    where</span>

<span class="sd">    - :math:`x_1, \dots, x_n` are the input vectors, which conceptually correspond to gradients submitted by honest and Byzantine participants during a training iteration.</span>

<span class="sd">    - :math:`\big|\big|.\big|\big|_2` denotes the \\(\\ell_2\\)-norm.</span>

<span class="sd">    - :math:`d` is the dimensionality of the input space, i.e., :math:`d` is the number of coordinates of vectors :math:`x_1, \dots, x_n`.</span>

<span class="sd">    </span>
<span class="sd">    Initialization parameters</span>
<span class="sd">    --------------------------</span>
<span class="sd">    nu : float, optional</span>
<span class="sd">        Smoothing parameter. Set to 0.1 by default.</span>
<span class="sd">    T : int, optional</span>
<span class="sd">         Number of iterations of the smoothed Weiszfeld algorithm. Set to 3 by default.</span>
<span class="sd">    </span>
<span class="sd">    Calling the instance</span>
<span class="sd">    --------------------</span>

<span class="sd">    Input parameters</span>
<span class="sd">    ----------------</span>
<span class="sd">    vectors: numpy.ndarray, torch.Tensor, list of numpy.ndarray or list of torch.Tensor</span>
<span class="sd">        A set of vectors, matrix or tensors.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    :numpy.ndarray or torch.Tensor</span>
<span class="sd">        The data type of the output will be the same as the input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import byzfl</span>
<span class="sd">    &gt;&gt;&gt; agg = byzfl.GeometricMedian()</span>

<span class="sd">    Using numpy arrays</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([[1., 2., 3.],       # np.ndarray</span>
<span class="sd">    &gt;&gt;&gt;               [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;               [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([3.78788764 4.78788764 5.78788764])</span>

<span class="sd">    Using torch tensors</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = torch.tensor([[1., 2., 3.],   # torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;                   [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;                   [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([3.7879, 4.7879, 5.7879])</span>

<span class="sd">    Using list of numpy arrays</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = [np.array([1., 2., 3.]),      # list of np.ndarray  </span>
<span class="sd">    &gt;&gt;&gt;      np.array([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      np.array([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([3.78788764 4.78788764 5.78788764])</span>

<span class="sd">    Using list of torch tensors</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = [torch.tensor([1., 2., 3.]),  # list of torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([3.7879, 4.7879, 5.7879])</span>


<span class="sd">    References</span>
<span class="sd">    ----------</span>

<span class="sd">    .. [1] Endre Weiszfeld. Sur le point pour lequel la somme des distances de </span>
<span class="sd">           n points donnés est minimum. Tohoku Mathematical Journal, First Series, </span>
<span class="sd">           43:355–386, 1937</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;f must be a float&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nu</span> <span class="o">=</span> <span class="n">nu</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">T</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;T must be a non-negative integer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="n">T</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectors</span><span class="p">):</span>
        <span class="n">tools</span><span class="p">,</span> <span class="n">vectors</span> <span class="o">=</span> <span class="n">check_vectors_type</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">vectors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="n">filtered_vectors</span> <span class="o">=</span> <span class="n">vectors</span><span class="p">[</span><span class="o">~</span><span class="n">tools</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">tools</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">vectors</span><span class="p">),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">):</span>
            <span class="n">betas</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">filtered_vectors</span> <span class="o">-</span> <span class="n">z</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">betas</span><span class="p">[</span><span class="n">betas</span><span class="o">&lt;</span><span class="bp">self</span><span class="o">.</span><span class="n">nu</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nu</span>
            <span class="n">betas</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha</span><span class="o">/</span><span class="n">betas</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">filtered_vectors</span><span class="o">*</span><span class="n">betas</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">tools</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">betas</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span></div>



<div class="viewcode-block" id="Krum">
<a class="viewcode-back" href="../../../aggregators/classes/krum.html#byzfl.Krum">[docs]</a>
<span class="k">class</span> <span class="nc">Krum</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Description</span>
<span class="sd">    -----------</span>

<span class="sd">    Apply the Krum aggregator [1]_:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \mathrm{Krum}_{f} \ (x_1, \dots, x_n) = x_{\lambda}</span>
<span class="sd">        </span>
<span class="sd">    with</span>

<span class="sd">    .. math::</span>

<span class="sd">        \lambda \in \argmin_{i \in \big[n\big]} \sum_{x \in \mathit{N}_i} \big|\big|x_i - x\big|\big|^2_2</span>

<span class="sd">    where</span>

<span class="sd">    - :math:`x_1, \dots, x_n` are the input vectors, which conceptually correspond to gradients submitted by honest and Byzantine participants during a training iteration.</span>

<span class="sd">    - :math:`f` conceptually represents the expected number of Byzantine vectors.</span>
<span class="sd">    </span>
<span class="sd">    - :math:`\big|\big|.\big|\big|_2` denotes the \\(\\ell_2\\)-norm.</span>
<span class="sd">    </span>
<span class="sd">    - For any \\(i \\in \\big[n\\big]\\), \\(\\mathit{N}_i\\) is the set of the \\(n − f\\) nearest neighbors of \\(x_i\\) in \\(\\{x_1, \\dots , x_n\\}\\).</span>

<span class="sd">    </span>
<span class="sd">    Initialization parameters</span>
<span class="sd">    --------------------------</span>
<span class="sd">    f : int, optional</span>
<span class="sd">        Number of faulty vectors. Set to 0 by default.</span>
<span class="sd">    </span>
<span class="sd">    Calling the instance</span>
<span class="sd">    --------------------</span>

<span class="sd">    Input parameters</span>
<span class="sd">    ----------------</span>
<span class="sd">    vectors: numpy.ndarray, torch.Tensor, list of numpy.ndarray or list of torch.Tensor</span>
<span class="sd">        A set of vectors, matrix or tensors.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    :numpy.ndarray or torch.Tensor</span>
<span class="sd">        The data type of the output will be the same as the input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import byzfl</span>
<span class="sd">    &gt;&gt;&gt; agg = byzfl.Krum(1)</span>

<span class="sd">    Using numpy arrays</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([[1., 2., 3.],       # np.ndarray</span>
<span class="sd">    &gt;&gt;&gt;               [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;               [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([1. 2. 3.])</span>

<span class="sd">    Using torch tensors</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = torch.tensor([[1., 2., 3.],   # torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;                   [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;                   [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([1., 2., 3.])</span>

<span class="sd">    Using list of numpy arrays</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = [np.array([1., 2., 3.]),      # list of np.ndarray  </span>
<span class="sd">    &gt;&gt;&gt;      np.array([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      np.array([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([1. 2. 3.])</span>

<span class="sd">    Using list of torch tensors</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = [torch.tensor([1., 2., 3.]),  # list of  torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([1., 2., 3.])</span>


<span class="sd">    References</span>
<span class="sd">    ----------</span>

<span class="sd">    .. [1] Peva Blanchard, El Mahdi El Mhamdi, Rachid Guer- raoui, and Julien</span>
<span class="sd">           Stainer. Machine learning with adversaries: Byzantine tolerant </span>
<span class="sd">           gradient descent. In I. Guyon, U. V. Luxburg, S. Bengio, H. </span>
<span class="sd">           Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, </span>
<span class="sd">           Advances in Neural Information Processing Systems 30, pages </span>
<span class="sd">           119–129. Curran Associates, Inc., 2017.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">f</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;f must be a non-negative integer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">=</span> <span class="n">f</span>
    
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectors</span><span class="p">):</span>
        <span class="n">tools</span><span class="p">,</span> <span class="n">vectors</span> <span class="o">=</span> <span class="n">check_vectors_type</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">&gt;=</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cannot tolerate 2f ≥ n. Got f=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="si">}</span><span class="s2">, n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">distance</span> <span class="o">=</span> <span class="n">distance_tool</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">vectors</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">:</span><span class="n">n</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">]</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">vectors</span><span class="p">[</span><span class="n">index</span><span class="p">]</span></div>



<div class="viewcode-block" id="MultiKrum">
<a class="viewcode-back" href="../../../aggregators/classes/multi_krum.html#byzfl.MultiKrum">[docs]</a>
<span class="k">class</span> <span class="nc">MultiKrum</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Description</span>
<span class="sd">    -----------</span>

<span class="sd">    Apply the Multi-Krum aggregator [1]_:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \mathrm{MultiKrum}_{f} \ (x_1, \dots, x_n) = \frac{1}{n-f}\sum_{i = 1}^{n-f} x_{\pi(i)}</span>
<span class="sd">        </span>
<span class="sd">    where</span>
<span class="sd">    </span>
<span class="sd">    - :math:`x_1, \dots, x_n` are the input vectors, which conceptually correspond to gradients submitted by honest and Byzantine participants during a training iteration.</span>

<span class="sd">    - :math:`f` conceptually represents the expected number of Byzantine vectors.</span>

<span class="sd">    - :math:`\big|\big|.\big|\big|_2` denotes the \\(\\ell_2\\)-norm.</span>

<span class="sd">    - For any \\(i \\in \\big[n\\big]\\), \\(\\mathit{N}_i\\) is the set of the \\(n - f\\) nearest neighbors of \\(x_i\\) in \\(\\{x_1, \\dots , x_n\\}\\).</span>

<span class="sd">    - \\(\\pi\\) denotes a permutation on \\(\\big[n\\big]\\) that sorts the input vectors in non-decreasing order of squared distance to their :math:`n-f` nearest neighbors. This sorting is expressed as:</span>

<span class="sd">    .. math:: \sum_{x \in \mathit{N}_{\pi(1)}} \big|\big|x_{\pi(1)} - x\big|\big|_2^2 \leq \dots \leq \sum_{x \in \mathit{N}_{\pi(n)}} \big|\big|x_{\pi(n)} - x\big|\big|_2^2</span>

<span class="sd">    </span>
<span class="sd">    Initialization parameters</span>
<span class="sd">    --------------------------</span>
<span class="sd">    f : int, optional</span>
<span class="sd">        Number of faulty vectors. Set to 0 by default.</span>
<span class="sd">    </span>
<span class="sd">    Calling the instance</span>
<span class="sd">    --------------------</span>

<span class="sd">    Input parameters</span>
<span class="sd">    ----------------</span>
<span class="sd">    vectors: numpy.ndarray, torch.Tensor, list of numpy.ndarray or list of torch.Tensor</span>
<span class="sd">        A set of vectors, matrix or tensors.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    :numpy.ndarray or torch.Tensor</span>
<span class="sd">        The data type of the output will be the same as the input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import byzfl</span>
<span class="sd">    &gt;&gt;&gt; agg = byzfl.MultiKrum(1)</span>

<span class="sd">    Using numpy arrays</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([[1., 2., 3.],       # np.ndarray</span>
<span class="sd">    &gt;&gt;&gt;               [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;               [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([2.5 3.5 4.5])</span>

<span class="sd">    Using torch tensors</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = torch.tensor([[1., 2., 3.],   # torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;                   [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;                   [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([2.5000, 3.5000, 4.5000])</span>

<span class="sd">    Using list of numpy arrays</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = [np.array([1., 2., 3.]),      # list of np.ndarray </span>
<span class="sd">    &gt;&gt;&gt;      np.array([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      np.array([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([2.5 3.5 4.5])</span>

<span class="sd">    Using list of torch tensors</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = [torch.tensor([1., 2., 3.]),  # list of torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([2.5000, 3.5000, 4.5000])</span>


<span class="sd">    References</span>
<span class="sd">    ----------</span>

<span class="sd">    .. [1] Peva Blanchard, El Mahdi El Mhamdi, Rachid Guerraoui, and Julien</span>
<span class="sd">           Stainer. Machine learning with adversaries: Byzantine tolerant </span>
<span class="sd">           gradient descent. In I. Guyon, U. V. Luxburg, S. Bengio, H. </span>
<span class="sd">           Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, </span>
<span class="sd">           Advances in Neural Information Processing Systems 30, pages </span>
<span class="sd">           119–129. Curran Associates, Inc., 2017.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">f</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;f must be a non-negative integer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">=</span> <span class="n">f</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectors</span><span class="p">):</span>
        <span class="n">tools</span><span class="p">,</span> <span class="n">vectors</span> <span class="o">=</span> <span class="n">check_vectors_type</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">&gt;=</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cannot tolerate 2f ≥ n. Got f=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="si">}</span><span class="s2">, n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">distance</span> <span class="o">=</span> <span class="n">distance_tool</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">vectors</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">:</span><span class="n">n</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">]</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">n</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">argpartition</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">)[:</span><span class="n">k</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">tools</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">vectors</span><span class="p">[</span><span class="n">indices</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>



<div class="viewcode-block" id="CenteredClipping">
<a class="viewcode-back" href="../../../aggregators/classes/centered_clipping.html#byzfl.CenteredClipping">[docs]</a>
<span class="k">class</span> <span class="nc">CenteredClipping</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Description</span>
<span class="sd">    -----------</span>

<span class="sd">    Apply the Centered Clipping aggregator [1]_:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \mathrm{CenteredClipping}_{m, L, \tau} \ (x_1, \dots, x_n) = v_{L}</span>
<span class="sd">        </span>
<span class="sd">    where</span>

<span class="sd">    - :math:`x_1, \dots, x_n` are the input vectors, which conceptually correspond to gradients submitted by honest and Byzantine participants during a training iteration.</span>

<span class="sd">    - :math:`\big|\big|.\big|\big|_2` denotes the \\(\\ell_2\\)-norm.</span>

<span class="sd">    - :math:`v_0 = m`.</span>

<span class="sd">    - :math:`v_{l+1} = v_{l} + \frac{1}{n}\sum_{i=1}^{n}(x_i - v_l)\min\left(1, \frac{\tau}{\big|\big|x_i - v_l\big|\big|_2}\right) \ \ ; \ \forall l \in \{0,\dots, L-1\}`.</span>

<span class="sd">    Initialization parameters</span>
<span class="sd">    --------------------------</span>
<span class="sd">    m : numpy.ndarray, torch.Tensor, optional</span>
<span class="sd">        Initial value of the CenteredClipping aggregator.</span>
<span class="sd">        Default (None) makes it start from zero, a vector with all its coordinates equal to 0.</span>
<span class="sd">    L : int, optional</span>
<span class="sd">        Number of iterations. Default is set to 1.</span>
<span class="sd">    tau : float, optional</span>
<span class="sd">          Clipping threshold. Default is set to 100.0.</span>

<span class="sd">    Calling the instance</span>
<span class="sd">    --------------------</span>

<span class="sd">    Input parameters</span>
<span class="sd">    ----------------</span>
<span class="sd">    vectors: numpy.ndarray, torch.Tensor, list of numpy.ndarray or list of torch.Tensor</span>
<span class="sd">        A set of vectors, matrix or tensors.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    :numpy.ndarray or torch.Tensor</span>
<span class="sd">        The data type of the output will be the same as the input.</span>

<span class="sd">    Note</span>
<span class="sd">    ----</span>

<span class="sd">        If the instance is called more than once, the value of \\(m\\) used in</span>
<span class="sd">        the next call is equal to the output vector of the previous call.</span>

<span class="sd">    Note</span>
<span class="sd">    ----</span>
<span class="sd">        </span>
<span class="sd">        In case the optional parameter \\(m\\) is specified when initializing </span>
<span class="sd">        the instance, \\(m\\) has to be of the same type and shape as the input</span>
<span class="sd">        vectors \\(\\{x_1, \\dots, x_n\\}\\) used when calling the instance.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import byzfl</span>
<span class="sd">    &gt;&gt;&gt; agg = byzfl.CenteredClipping()</span>

<span class="sd">    Using numpy arrays</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([[1., 2., 3.],       # np.ndarray</span>
<span class="sd">    &gt;&gt;&gt;               [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;               [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([4., 5., 6.])</span>
<span class="sd">    </span>
<span class="sd">    Using torch tensors</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = torch.tensor([[1., 2., 3.],   # torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;                   [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;                   [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([4., 5., 6.])</span>

<span class="sd">    Using list of numpy arrays</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = [np.array([1., 2., 3.]),      # list of np.ndarray </span>
<span class="sd">    &gt;&gt;&gt;      np.array([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      np.array([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([4., 5., 6.])</span>
<span class="sd">    </span>
<span class="sd">    Using list of torch tensors</span>

<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = [torch.tensor([1., 2., 3.]),  # list of torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([4., 5., 6.])</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>

<span class="sd">    .. [1] Sai Praneeth Karimireddy, Lie He, and Martin Jaggi. Learning</span>
<span class="sd">           from history for byzantine robust optimization. In 38th</span>
<span class="sd">           International Conference on Machine Learning (ICML), 2021.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">L</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="mf">100.0</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">m</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;m must be of type np.ndarray or torch.Tensor&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">m</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">L</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;L must be a non-negative integer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">L</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tau</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">or</span> <span class="n">tau</span> <span class="o">&lt;</span> <span class="mf">0.</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;tau must be a non-negative float&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="n">tau</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectors</span><span class="p">):</span>
        <span class="n">tools</span><span class="p">,</span> <span class="n">vectors</span> <span class="o">=</span> <span class="n">check_vectors_type</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">vectors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">):</span>
            <span class="n">differences</span> <span class="o">=</span> <span class="n">vectors</span> <span class="o">-</span> <span class="n">v</span>
            <span class="n">clip_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">/</span> <span class="n">tools</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">differences</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">clip_factor</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">tools</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">clip_factor</span><span class="p">),</span> <span class="n">clip_factor</span><span class="p">)</span>
            <span class="n">differences</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">differences</span><span class="p">,</span> <span class="n">clip_factor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">tools</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">differences</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">v</span>
        <span class="k">return</span> <span class="n">v</span></div>



<div class="viewcode-block" id="MDA">
<a class="viewcode-back" href="../../../aggregators/classes/mda.html#byzfl.MDA">[docs]</a>
<span class="k">class</span> <span class="nc">MDA</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Description</span>
<span class="sd">    -----------</span>

<span class="sd">    Apply the Minimum Diameter Averaging aggregator [1]_:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \mathrm{MDA}_{f} \ (x_1, \dots, x_n) = \frac{1}{n-f} \sum_{i\in S^\star} x_i</span>
<span class="sd">        </span>
<span class="sd">    where</span>

<span class="sd">    - :math:`x_1, \dots, x_n` are the input vectors, which conceptually correspond to gradients submitted by honest and Byzantine participants during a training iteration.</span>

<span class="sd">    - :math:`f` conceptually represents the expected number of Byzantine vectors.</span>

<span class="sd">    - :math:`\big|\big|.\big|\big|_2` denotes the \\(\\ell_2\\)-norm.</span>

<span class="sd">    - .. math:: S^\star \in \argmin_{\substack{S \subset \{1,\dots,n\} \\ |S|=n-f}} \left\{\max_{i,j \in S} \big|\big|x_i - x_j\big|\big|_2\right\}.</span>
<span class="sd">    </span>
<span class="sd">    Initialization parameters</span>
<span class="sd">    --------------------------</span>
<span class="sd">    f : int, optional</span>
<span class="sd">        Number of faulty vectors. Set to 0 by default.</span>

<span class="sd">    Calling the instance</span>
<span class="sd">    --------------------</span>

<span class="sd">    Input parameters</span>
<span class="sd">    ----------------</span>
<span class="sd">    vectors: numpy.ndarray, torch.Tensor, list of numpy.ndarray or list of torch.Tensor</span>
<span class="sd">        A set of vectors, matrix or tensors.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    :numpy.ndarray or torch.Tensor</span>
<span class="sd">        The data type of the output will be the same as the input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import byzfl</span>
<span class="sd">    &gt;&gt;&gt; agg = byzfl.MDA(1)</span>

<span class="sd">    Using numpy arrays</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([[1., 2., 3.],       # np.ndarray</span>
<span class="sd">    &gt;&gt;&gt;               [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;               [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([2.5, 3.5, 4.5])</span>

<span class="sd">    Using torch tensors</span>

<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = torch.tensor([[1., 2., 3.],   # torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;                   [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;                   [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([2.5000, 3.5000, 4.5000])</span>

<span class="sd">    Using list of numpy arrays</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = [np.array([1., 2., 3.]),      # list of np.ndarray </span>
<span class="sd">    &gt;&gt;&gt;      np.array([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      np.array([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([2.5, 3.5, 4.5])</span>
<span class="sd">    </span>
<span class="sd">    Using list of torch tensors</span>

<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = [torch.tensor([1., 2., 3.]),  # list of torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([2.5000, 3.5000, 4.5000])</span>


<span class="sd">    References</span>
<span class="sd">    ----------</span>

<span class="sd">    .. [1] El Mhamdi, E. M., Guerraoui, R., Guirguis, A., Hoang, L. N., and </span>
<span class="sd">           Rouault, S. Genuinely distributed byzantine machine learning. In </span>
<span class="sd">           Proceedings of the 39th Symposium on Principles of Distributed </span>
<span class="sd">           Computing, pp. 355–364, 2020.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">f</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;f must be a non-negative integer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">=</span> <span class="n">f</span>
    
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectors</span><span class="p">):</span>
        <span class="n">tools</span><span class="p">,</span> <span class="n">vectors</span> <span class="o">=</span> <span class="n">check_vectors_type</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">&gt;=</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cannot tolerate 2f ≥ n. Got f=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="si">}</span><span class="s2">, n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">distance</span> <span class="o">=</span> <span class="n">distance_tool</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">vectors</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">n</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span>

        <span class="n">min_diameter</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="n">min_subset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
        <span class="n">all_subsets</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">combinations</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">k</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">subset</span> <span class="ow">in</span> <span class="n">all_subsets</span><span class="p">:</span>
            <span class="n">vector_indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">combinations</span><span class="p">(</span><span class="n">subset</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
            <span class="n">diameter</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dist</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">vector_indices</span><span class="p">))])</span>
            <span class="k">if</span> <span class="n">diameter</span> <span class="o">&lt;</span> <span class="n">min_diameter</span><span class="p">:</span>
                <span class="n">min_subset</span> <span class="o">=</span> <span class="n">subset</span>
                <span class="n">min_diameter</span> <span class="o">=</span> <span class="n">diameter</span>
        <span class="k">return</span> <span class="n">vectors</span><span class="p">[</span><span class="n">tools</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">min_subset</span><span class="p">)]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>



<div class="viewcode-block" id="MoNNA">
<a class="viewcode-back" href="../../../aggregators/classes/monna.html#byzfl.MoNNA">[docs]</a>
<span class="k">class</span> <span class="nc">MoNNA</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Description</span>
<span class="sd">    -----------</span>

<span class="sd">    Apply the MoNNA aggregator [1]_:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \mathrm{MoNNA}_{f, \mathrm{idx}} \ (x_1, \dots, x_n) = \frac{1}{n-f} \sum_{i \in \mathit{N}_{\mathrm{idx}+1}} x_{i}</span>
<span class="sd">        </span>
<span class="sd">    where</span>
<span class="sd">    </span>
<span class="sd">    - :math:`x_1, \dots, x_n` are the input vectors, which conceptually correspond to gradients submitted by honest and Byzantine participants during a training iteration.</span>

<span class="sd">    - :math:`f` conceptually represents the expected number of Byzantine vectors.</span>

<span class="sd">    - \\(\\mathit{N}_{i}\\) is the set of the \\(n − f\\) nearest neighbors of \\(x_{i}\\) in \\(\\{x_1, \\dots , x_n\\}\\).</span>

<span class="sd">    - :math:`\mathrm{idx} \in \{0, \dots, n-1\}` is the ID of the chosen worker/vector for which the neighborhood is computed. In other words, :math:`x_{\mathrm{idx}+1}` is the vector sent by the worker with ID :math:`\mathrm{idx}`.</span>

<span class="sd">    Therefore, MoNNA computes the average of the \\(n − f\\) nearest neighbors of the chosen vector with ID :math:`\mathrm{idx}`.</span>
<span class="sd">    </span>

<span class="sd">    Initialization parameters</span>
<span class="sd">    --------------------------</span>
<span class="sd">    f : int, optional</span>
<span class="sd">        Number of faulty vectors. Set to 0 by default.</span>
<span class="sd">    idx : int, optional</span>
<span class="sd">        Index of the vector for which the neighborhood is computed. Set to 0 by default.</span>

<span class="sd">    Calling the instance</span>
<span class="sd">    --------------------</span>

<span class="sd">    Input parameters</span>
<span class="sd">    ----------------</span>

<span class="sd">    vectors: numpy.ndarray, torch.Tensor, list of numpy.ndarray or list of torch.Tensor</span>
<span class="sd">        A set of vectors, matrix or tensors.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    :numpy.ndarray or torch.Tensor</span>
<span class="sd">        The data type of the output will be the same as the input.</span>

<span class="sd">    Note</span>
<span class="sd">    ----</span>

<span class="sd">    MoNNA is used in peer-to-peer settings where :math:`\mathrm{idx}` corresponds to the ID of a vector that is trusted to be correct (i.e., not faulty).</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import byzfl</span>
<span class="sd">    &gt;&gt;&gt; agg = byzfl.MoNNA(1, 1)</span>

<span class="sd">    Using numpy arrays</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([[1., 2., 3.],       # np.ndarray</span>
<span class="sd">    &gt;&gt;&gt;               [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;               [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([2.5, 3.5, 4.5])</span>

<span class="sd">    Using torch tensors</span>

<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = torch.tensor([[1., 2., 3.],   # torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;                   [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;                   [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([2.5000, 3.5000, 4.5000])</span>

<span class="sd">    Using list of numpy arrays</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = [np.array([1., 2., 3.]),      # list of np.ndarray </span>
<span class="sd">    &gt;&gt;&gt;      np.array([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      np.array([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([2.5, 3.5, 4.5])</span>
<span class="sd">    </span>
<span class="sd">    Using list of torch tensors</span>

<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = [torch.tensor([1., 2., 3.]),  # list of torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([2.5000, 3.5000, 4.5000])</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>

<span class="sd">    .. [1] Farhadkhani, S., Guerraoui, R., Gupta, N., Hoang, L. N., Pinot, R.,</span>
<span class="sd">           &amp; Stephan, J. (2023, July). Robust collaborative learning with </span>
<span class="sd">           linear gradient overhead. In International Conference on Machine </span>
<span class="sd">           Learning (pp. 9761-9813). PMLR. </span>

<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">f</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;f must be a non-negative integer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">=</span> <span class="n">f</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;idx must be a non-negative integer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">idx</span> <span class="o">=</span> <span class="n">idx</span>
    
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectors</span><span class="p">):</span>
        <span class="n">tools</span><span class="p">,</span> <span class="n">vectors</span> <span class="o">=</span> <span class="n">check_vectors_type</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">&gt;=</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cannot tolerate 2f ≥ n. Got f=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="si">}</span><span class="s2">, n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;idx must be smaller than n, but got idx=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="si">}</span><span class="s2"> and n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">distance</span> <span class="o">=</span> <span class="n">distance_tool</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">vectors</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">n</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">argpartition</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">)[:</span><span class="n">k</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">tools</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">vectors</span><span class="p">[</span><span class="n">indices</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>



<div class="viewcode-block" id="Meamed">
<a class="viewcode-back" href="../../../aggregators/classes/meamed.html#byzfl.Meamed">[docs]</a>
<span class="k">class</span> <span class="nc">Meamed</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Description</span>
<span class="sd">    -----------</span>

<span class="sd">    Compute the mean around median along the first axis [1]_:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \big[\mathrm{Meamed}_{f}(x_1, \ldots, x_n)\big]_k = \frac{1}{n-f} \sum_{j=1}^{n-f} \big[x_{\pi(j)}\big]_k</span>
<span class="sd">    </span>
<span class="sd">    where </span>
<span class="sd">    </span>
<span class="sd">    - :math:`x_1, \dots, x_n` are the input vectors, which conceptually correspond to gradients submitted by honest and Byzantine participants during a training iteration.</span>

<span class="sd">    - :math:`f` conceptually represents the expected number of Byzantine vectors.</span>
<span class="sd">    </span>
<span class="sd">    - \\(\\big[\\cdot\\big]_k\\) refers to the \\(k\\)-th coordinate.</span>

<span class="sd">    - :math:`\mathrm{median}` refers to the median of :math:`n` scalars.</span>

<span class="sd">    - \\(\\pi\\) denotes a permutation on \\(\\big[n\\big]\\) that sorts the input vectors based on their \\(k\\)-th coordinate in non-decreasing order of distance to the :math:`\mathrm{median}` of the \\(k\\)-th coordinate across the input vectors. This sorting is expressed as:</span>
<span class="sd">    </span>
<span class="sd">    :math:`\Big|\big[x_{\pi_k(1)}\big]_k - \mathrm{median}\big(\big[x_1\big]_k, \ldots, \big[x_n\big]_k\big)\Big| \leq \ldots \leq \Big|\big[x_{\pi_k(n)}\big]_k - \mathrm{median}\big(\big[x_1\big]_k, \ldots, \big[x_n\big]_k\big)\Big|`.</span>
<span class="sd">    </span>
<span class="sd">    In other words, Meamed computes the average of the \\(n-f\\) closest elements to the :math:`\mathrm{median}` for each dimension \\(k\\).</span>

<span class="sd">    Initialization parameters</span>
<span class="sd">    --------------------------</span>
<span class="sd">    f : int, optional</span>
<span class="sd">        Number of faulty vectors. Set to 0 by default.</span>

<span class="sd">    Calling the instance</span>
<span class="sd">    --------------------</span>

<span class="sd">    Input parameters</span>
<span class="sd">    ----------------</span>

<span class="sd">    vectors: numpy.ndarray, torch.Tensor, list of numpy.ndarray or list of torch.Tensor</span>
<span class="sd">        A set of vectors, matrix or tensors.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    :numpy.ndarray or torch.Tensor</span>
<span class="sd">        The data type of the output will be the same as the input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; import byzfl</span>
<span class="sd">    &gt;&gt;&gt; agg = byzfl.Meamed(1)</span>

<span class="sd">    Using numpy arrays</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([[1., 2., 3.],       # np.ndarray</span>
<span class="sd">    &gt;&gt;&gt;               [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;               [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([2.5, 3.5, 4.5])</span>

<span class="sd">    Using torch tensors</span>

<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = torch.tensor([[1., 2., 3.],   # torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;                   [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;                   [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([2.5000, 3.5000, 4.5000])</span>

<span class="sd">    Using list of numpy arrays</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = [np.array([1., 2., 3.]),      # list of np.ndarray </span>
<span class="sd">    &gt;&gt;&gt;      np.array([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      np.array([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([2.5, 3.5, 4.5])</span>
<span class="sd">    </span>
<span class="sd">    Using list of torch tensors</span>

<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = [torch.tensor([1., 2., 3.]),  # list of torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([2.5000, 3.5000, 4.5000])</span>


<span class="sd">    References</span>
<span class="sd">    ----------</span>

<span class="sd">    .. [1] Xie, C., Koyejo, O., and Gupta, I. Generalized byzantine-tolerant sgd, 2018.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">f</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;f must be a non-negative integer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">=</span> <span class="n">f</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectors</span><span class="p">):</span>
        <span class="n">tools</span><span class="p">,</span> <span class="n">vectors</span> <span class="o">=</span> <span class="n">check_vectors_type</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">&gt;=</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cannot tolerate 2f ≥ n. Got f=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="si">}</span><span class="s2">, n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="n">d</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vectors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">k</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span>
        <span class="n">median</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">abs_diff</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">vectors</span> <span class="o">-</span> <span class="n">median</span><span class="p">))</span>

        <span class="n">indices</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">argpartition</span><span class="p">(</span><span class="n">abs_diff</span><span class="p">,</span> <span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[:</span><span class="n">k</span><span class="p">]</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tools</span> <span class="o">==</span> <span class="n">np</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">indices</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tools</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">vectors</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">indices</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>



<div class="viewcode-block" id="CAF">
<a class="viewcode-back" href="../../../aggregators/classes/caf.html#byzfl.CAF">[docs]</a>
<span class="k">class</span> <span class="nc">CAF</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Description</span>
<span class="sd">    -----------</span>

<span class="sd">    Implements the **Covariance-bound Agnostic Filter** (CAF) [1]_, a robust aggregator</span>
<span class="sd">    designed to tolerate Byzantine inputs without requiring a bound on the covariance</span>
<span class="sd">    of honest vectors.</span>

<span class="sd">    The algorithm iteratively estimates a robust mean by downweighting samples whose</span>
<span class="sd">    deviations from the mean are aligned with the dominant eigenvector of the</span>
<span class="sd">    empirical covariance matrix.</span>

<span class="sd">    Precisely, given a set of input vectors :math:`x_1, \dots, x_n \in \mathbb{R}^d`,</span>
<span class="sd">    the algorithm proceeds as follows:</span>

<span class="sd">    1. Initialize weights :math:`c_i = 1` for all :math:`i \in [n]`.</span>
<span class="sd">    2. Repeat until the total weight :math:`\sum_i c_i \leq n - 2f`:</span>
<span class="sd">        - Compute the weighted empirical mean:</span>

<span class="sd">          .. math::</span>
<span class="sd">             \mu_c = \frac{1}{\sum_i c_i} \sum_{i=1}^n c_i x_i</span>

<span class="sd">        - Using the power method [2]_, compute the dominant eigenvector :math:`v` and maximum eigenvalue :math:`\lambda_{max}` of the empirical covariance matrix:</span>

<span class="sd">          .. math::</span>
<span class="sd">             \Sigma_c = \frac{1}{\sum_i c_i} \sum_{i=1}^n c_i (x_i - \mu_c)(x_i - \mu_c)^\top</span>

<span class="sd">        - For each vector, compute the projection squared:</span>

<span class="sd">          .. math::</span>
<span class="sd">             \tau_i = ((x_i - \mu_c)^\top v)^2</span>

<span class="sd">        - Downweight outliers:</span>

<span class="sd">          .. math::</span>
<span class="sd">             c_i \leftarrow c_i \cdot \left(1 - \frac{\tau_i}{\max_j \tau_j}\right)</span>

<span class="sd">    3. Return the empirical mean :math:`\mu_c` corresponding to the smallest maximum eigenvalue :math:`\lambda_{max}` encountered.</span>

<span class="sd">    This algorithm does not assume any upper bound on the spectral norm of the covariance matrix</span>
<span class="sd">    and is especially suited to settings with high-dimensional or heterogeneously distributed data.</span>

<span class="sd">    Initialization parameters</span>
<span class="sd">    --------------------------</span>
<span class="sd">    f : int, optional</span>
<span class="sd">        Number of faulty vectors. Set to 0 by default.</span>

<span class="sd">    Calling the instance</span>
<span class="sd">    --------------------</span>

<span class="sd">    Input parameters</span>
<span class="sd">    ----------------</span>

<span class="sd">    vectors: numpy.ndarray, torch.Tensor, list of numpy.ndarray or list of torch.Tensor</span>
<span class="sd">        A set of vectors, matrix or tensors.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    :numpy.ndarray or torch.Tensor</span>
<span class="sd">        The data type of the output will be the same as the input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    &gt;&gt;&gt; import byzfl</span>
<span class="sd">    &gt;&gt;&gt; agg = byzfl.CAF(1)</span>

<span class="sd">    Using numpy arrays</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([[1., 2., 3.],       # np.ndarray</span>
<span class="sd">    &gt;&gt;&gt;               [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;               [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([4. 5. 6.])</span>

<span class="sd">    Using torch tensors</span>

<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = torch.tensor([[1., 2., 3.],   # torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;                   [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;                   [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([4., 5., 6.])</span>

<span class="sd">    Using list of numpy arrays</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = [np.array([1., 2., 3.]),      # list of np.ndarray  </span>
<span class="sd">    &gt;&gt;&gt;      np.array([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      np.array([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([4., 5., 6.])</span>

<span class="sd">    Using list of torch tensors</span>

<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = [torch.tensor([1., 2., 3.]),  # list of torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([4., 5., 6.])</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Allouah, Y., Guerraoui, R., and Stephan, J. Towards Trustworthy Federated Learning with Untrusted Participants. ICML, 2025.</span>
<span class="sd">    .. [2] Golub, G. H., &amp; Van Loan, C. F. (2013). Matrix Computations (4th ed.). Johns Hopkins University Press.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">f</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;f must be a non-negative integer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">=</span> <span class="n">f</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectors</span><span class="p">):</span>
        <span class="n">tools</span><span class="p">,</span> <span class="n">vectors</span> <span class="o">=</span> <span class="n">check_vectors_type</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">dimension</span> <span class="o">=</span> <span class="n">shape</span><span class="p">(</span><span class="n">tools</span><span class="p">,</span> <span class="n">vectors</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">&gt;=</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cannot tolerate 2f ≥ n. Got f=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="si">}</span><span class="s2">, n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">compute_dominant_eigenvector</span><span class="p">(</span><span class="n">tools</span><span class="p">,</span> <span class="n">vectors</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">diffs</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">max_iters</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
            <span class="c1"># Compute the dominant eigenvector using a weighted sum approach.</span>
            <span class="k">if</span> <span class="n">tools</span> <span class="o">==</span> <span class="n">np</span><span class="p">:</span>
                <span class="n">vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">dimension</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">dimension</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">vectors</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">vector</span> <span class="o">=</span> <span class="n">vector</span> <span class="o">/</span> <span class="n">tools</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span>

            <span class="n">eigenvalue</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iters</span><span class="p">):</span>
                <span class="c1"># Weighted sum for matrix-vector product</span>
                <span class="n">dot_products</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">diffs</span><span class="p">,</span> <span class="n">vector</span><span class="p">)</span> <span class="c1"># (x_i - mu_c) · vector</span>
                <span class="n">weighted_sum</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">c</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">diffs</span> <span class="o">*</span> <span class="n">dot_products</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">tools</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
                <span class="c1"># Normalize the vector</span>
                <span class="n">next_vector</span> <span class="o">=</span> <span class="n">weighted_sum</span> <span class="o">/</span> <span class="n">tools</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">weighted_sum</span><span class="p">)</span>
                <span class="c1"># Compute eigenvalue as Rayleigh quotient</span>
                <span class="n">next_eigenvalue</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">next_vector</span><span class="p">,</span> <span class="n">weighted_sum</span><span class="p">)</span>

                <span class="n">vector</span> <span class="o">=</span> <span class="n">next_vector</span>
                <span class="n">eigenvalue</span> <span class="o">=</span> <span class="n">next_eigenvalue</span>

            <span class="k">return</span> <span class="n">eigenvalue</span><span class="p">,</span> <span class="n">next_vector</span>

        <span class="n">c</span> <span class="o">=</span> <span class="n">ones_vector</span><span class="p">(</span><span class="n">tools</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">vectors</span><span class="p">)</span>
        <span class="n">c_sum</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
        <span class="n">eigen_val</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>

        <span class="n">best_mu_c</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">while</span> <span class="n">c_sum</span> <span class="o">&gt;</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">:</span>
            <span class="c1"># Compute the empirical mean</span>
            <span class="n">weighted_sum</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">c</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">vectors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">current_mu_c</span> <span class="o">=</span> <span class="n">weighted_sum</span> <span class="o">/</span> <span class="n">c_sum</span>

            <span class="c1"># Compute the maximum eigenvector and eigenvalue of the empirical covariance matrix</span>
            <span class="n">diffs</span> <span class="o">=</span> <span class="n">vectors</span> <span class="o">-</span> <span class="n">current_mu_c</span>      <span class="c1"># Compute (x_i - current_mu_c)</span>
            <span class="n">max_eigen_val</span><span class="p">,</span> <span class="n">max_eigen_vec</span> <span class="o">=</span> <span class="n">compute_dominant_eigenvector</span><span class="p">(</span><span class="n">tools</span><span class="p">,</span> <span class="n">vectors</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">diffs</span><span class="p">,</span> <span class="n">dimension</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">max_eigen_val</span> <span class="o">&lt;</span> <span class="n">eigen_val</span><span class="p">:</span>
                <span class="n">eigen_val</span> <span class="o">=</span> <span class="n">max_eigen_val</span>
                <span class="n">best_mu_c</span> <span class="o">=</span> <span class="n">current_mu_c</span>

            <span class="c1"># Compute tau values</span>
            <span class="n">tau</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">diffs</span><span class="p">,</span> <span class="n">max_eigen_vec</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="c1"># Update weights</span>
            <span class="n">tau_max</span> <span class="o">=</span> <span class="n">tau</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
            <span class="n">c</span> <span class="o">=</span> <span class="n">c</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tau</span> <span class="o">/</span> <span class="n">tau_max</span><span class="p">)</span>
            <span class="n">c_sum</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>

        <span class="c1"># Return the empirical mean with smallest max_eigen_val encountered</span>
        <span class="k">return</span> <span class="n">best_mu_c</span></div>



<div class="viewcode-block" id="SMEA">
<a class="viewcode-back" href="../../../aggregators/classes/smea.html#byzfl.SMEA">[docs]</a>
<span class="k">class</span> <span class="nc">SMEA</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Description</span>
<span class="sd">    -----------</span>

<span class="sd">    Implements the **Smallest Maximum Eigenvalue Averaging (SMEA)** rule [1]_, a robust aggregation</span>
<span class="sd">    method that selects the subset of client vectors whose covariance has the lowest maximum</span>
<span class="sd">    eigenvalue, then returns their average.</span>

<span class="sd">    Formally, given a set of input vectors :math:`x_1, \dots, x_n \in \mathbb{R}^d` and an integer </span>
<span class="sd">    :math:`f` representing the number of potential Byzantine vectors, the algorithm proceeds as follows:</span>

<span class="sd">    1. Enumerate all subsets :math:`S \subset [n]` of size :math:`n - f`.</span>
<span class="sd">    2. For each subset :math:`S`, compute its empirical mean:</span>

<span class="sd">       .. math::</span>
<span class="sd">          \mu_S = \frac{1}{|S|} \sum_{i \in S} x_i</span>

<span class="sd">    3. Compute the empirical covariance matrix:</span>

<span class="sd">       .. math::</span>
<span class="sd">          \Sigma_S = \frac{1}{|S|} \sum_{i \in S} (x_i - \mu_S)(x_i - \mu_S)^\top</span>

<span class="sd">    4. Using the power method [2]_, compute the maximum eigenvalue :math:`\lambda_{\max}(\Sigma_S)` of each subset’s covariance.</span>
<span class="sd">    5. Select the subset :math:`S^\star` that minimizes the maximum eigenvalue:</span>

<span class="sd">       .. math::</span>
<span class="sd">          S^\star = \arg\min_{S: |S|=n-f} \lambda_{\max}(\Sigma_S)</span>

<span class="sd">    6. Return the empirical mean of the optimal subset :math:`S^\star`:</span>

<span class="sd">       .. math::</span>
<span class="sd">          \text{SMEA}(x_1, \dots, x_n) = \frac{1}{|S^\star|} \sum_{i \in S^\star} x_i</span>

<span class="sd">    While computationally expensive due to its combinatorial nature, SMEA provides state-of-the-art robustness </span>
<span class="sd">    guarantees [1]_. This method is thus particularly well-suited to federated settings where the number of clients is not too large.</span>

<span class="sd">    Initialization parameters</span>
<span class="sd">    --------------------------</span>
<span class="sd">    f : int, optional</span>
<span class="sd">        Number of faulty vectors. Set to 0 by default.</span>

<span class="sd">    Calling the instance</span>
<span class="sd">    --------------------</span>

<span class="sd">    Input parameters</span>
<span class="sd">    ----------------</span>

<span class="sd">    vectors: numpy.ndarray, torch.Tensor, list of numpy.ndarray or list of torch.Tensor</span>
<span class="sd">        A set of vectors, matrix or tensors.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    :numpy.ndarray or torch.Tensor</span>
<span class="sd">        The data type of the output will be the same as the input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import byzfl</span>
<span class="sd">    &gt;&gt;&gt; agg = byzfl.SMEA(1)</span>

<span class="sd">    Using numpy arrays</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([[1., 2., 3.],       # np.ndarray</span>
<span class="sd">    &gt;&gt;&gt;               [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;               [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([2.5, 3.5, 4.5])</span>

<span class="sd">    Using torch tensors</span>

<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = torch.tensor([[1., 2., 3.],   # torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;                   [4., 5., 6.], </span>
<span class="sd">    &gt;&gt;&gt;                   [7., 8., 9.]])</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([2.5000, 3.5000, 4.5000])</span>

<span class="sd">    Using list of numpy arrays</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = [np.array([1., 2., 3.]),      # list of np.ndarray  </span>
<span class="sd">    &gt;&gt;&gt;      np.array([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      np.array([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    array([2.5, 3.5, 4.5])</span>

<span class="sd">    Using list of torch tensors</span>

<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; x = [torch.tensor([1., 2., 3.]),  # list of torch.tensor </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([4., 5., 6.]), </span>
<span class="sd">    &gt;&gt;&gt;      torch.tensor([7., 8., 9.])]</span>
<span class="sd">    &gt;&gt;&gt; agg(x)</span>
<span class="sd">    tensor([2.5000, 3.5000, 4.5000])</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Y Allouah, R Guerraoui, N Gupta, R Pinot, J Stephan. On the Privacy-Robustness-Utility Trilemma in Distributed Learning. ICML, 2023.</span>
<span class="sd">    .. [2] Golub, G. H., &amp; Van Loan, C. F. (2013). Matrix Computations (4th ed.). Johns Hopkins University Press.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">f</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;f must be a non-negative integer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">=</span> <span class="n">f</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectors</span><span class="p">):</span>

        <span class="n">tools</span><span class="p">,</span> <span class="n">vectors</span> <span class="o">=</span> <span class="n">check_vectors_type</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">dimension</span> <span class="o">=</span> <span class="n">shape</span><span class="p">(</span><span class="n">tools</span><span class="p">,</span> <span class="n">vectors</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">&gt;=</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Too many Byzantine clients (2f &gt;= n). Got f=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="si">}</span><span class="s2">, n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">compute_dominant_eigenvector</span><span class="p">(</span><span class="n">diffs</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">max_iters</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">tools</span> <span class="o">==</span> <span class="n">np</span><span class="p">:</span>
                <span class="n">vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">dimension</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">dimension</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">diffs</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">vector</span> <span class="o">=</span> <span class="n">vector</span> <span class="o">/</span> <span class="n">tools</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span>

            <span class="n">eigenvalue</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iters</span><span class="p">):</span>
                <span class="n">dot_products</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">diffs</span><span class="p">,</span> <span class="n">vector</span><span class="p">)</span>
                <span class="n">weighted_sum</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">diffs</span> <span class="o">*</span> <span class="n">dot_products</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">next_vector</span> <span class="o">=</span> <span class="n">weighted_sum</span> <span class="o">/</span> <span class="n">tools</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">weighted_sum</span><span class="p">)</span>
                <span class="n">next_eigenvalue</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">next_vector</span><span class="p">,</span> <span class="n">weighted_sum</span><span class="p">)</span>

                <span class="n">vector</span> <span class="o">=</span> <span class="n">next_vector</span>
                <span class="n">eigenvalue</span> <span class="o">=</span> <span class="n">next_eigenvalue</span>

            <span class="k">return</span> <span class="n">eigenvalue</span><span class="p">,</span> <span class="n">next_vector</span>

        <span class="k">def</span> <span class="nf">compute_min_subset</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">nb_byz</span><span class="p">):</span>
            <span class="n">min_eigenvalue</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
            <span class="n">min_subset</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">for</span> <span class="n">subset</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">combinations</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">n</span> <span class="o">-</span> <span class="n">nb_byz</span><span class="p">):</span>
                <span class="n">subset_grads</span> <span class="o">=</span> <span class="n">vectors</span><span class="p">[</span><span class="n">tools</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">subset</span><span class="p">)]</span>

                <span class="n">avg</span> <span class="o">=</span> <span class="n">tools</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">subset_grads</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">diffs</span> <span class="o">=</span> <span class="n">subset_grads</span> <span class="o">-</span> <span class="n">avg</span>
                <span class="n">max_eigen_val</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">compute_dominant_eigenvector</span><span class="p">(</span><span class="n">diffs</span><span class="p">,</span> <span class="n">dimension</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">max_eigen_val</span> <span class="o">&lt;</span> <span class="n">min_eigenvalue</span><span class="p">:</span>
                    <span class="n">min_eigenvalue</span> <span class="o">=</span> <span class="n">max_eigen_val</span>
                    <span class="n">min_subset</span> <span class="o">=</span> <span class="n">subset</span>

            <span class="k">return</span> <span class="n">min_subset</span>

        <span class="n">selected_subset</span> <span class="o">=</span> <span class="n">compute_min_subset</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">vectors</span><span class="p">[</span><span class="n">tools</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">selected_subset</span><span class="p">)]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>

</pre></div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024, EPFL.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.4.7.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.0.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>